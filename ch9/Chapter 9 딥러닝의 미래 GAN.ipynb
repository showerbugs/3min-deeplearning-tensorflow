{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9 딥러닝의 미래 GAN\n",
    "\n",
    "GAN(Generative Adversarial Network)는 서로 대립하는 두 신경망을 경쟁시켜가며 결과물을 생성하는 방법을 학습하는 모델입니다.\n",
    "\n",
    "> 위조지폐범(생성자)와 경찰(구분자)가 있다고 가정합시다. 위조지폐범은 경찰을 속이려고 노력하고, 경찰은 위조한 지폐를 감별하려고 최대한 노력합니다. 이를 통해 서로의 능력이 발전하고, 위조지폐범은 진짜와 거의 구별되지 않는 위조지폐를 만들 수 있게 됩니다.\n",
    "\n",
    "신경망 모델로 나타내면 아래와 같습니다\n",
    "\n",
    "![GAN_1](GAN_1.png)\n",
    "\n",
    "1. 먼저 실제 이미지를 주고 구분자(Discriminator)에게 이 이미지가 진짜임을 판단하게 합니다.\n",
    "2. 생성자(Generator)를 통해 임의의 이미지를 만들고 이것을 다시 같은 구분자를 통해 진짜 이미지인지를 판단하게 합니다.\n",
    "3. 생성자는 구분자를 속여 진짜처럼 보이게 하고, 구분자는 생성자가 만든 이미지를 최대한 가짜라고 구분하도록 훈련한다.\n",
    "\n",
    "이런 경쟁을 통해 생성자는 실제 이미지와 상당히 비슷한 이미지를 생성하게 된다.\n",
    "\n",
    "1. 사진을 고흐 풍 그림으로 다시 그리기\n",
    "2. 선으로만 그려진 만화를 채색\n",
    "3. 모자이크 없애기\n",
    "4. 자연어 문장 생성 등등\n",
    "\n",
    "![GAN_2](GAN_2.png)\n",
    "\n",
    "이번 장에서는 GAN 모델을 이용해 MNIST 손글씨를 무작위로 생성하고, 이를 학습하여 원하는 숫자의 이미지를 생성하는 모델을 만들어보겠습니다.\n",
    "\n",
    "## 9.1 GAN 기본 모델 구현하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "n_hidden = 255\n",
    "n_input = 28 * 28\n",
    "n_noise = 128 # 생성자의 입력값으로 사용할 노이즈의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN도 비지도 학습이므로 오토인코더처럼 Y(Labeling) 데이터를 사용하지 않습니다.\n",
    "\n",
    "# 이미지를 넣을 X와 이미지에 들어가는 노이즈를 넣을 Z를 추가한다.\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 신경망에 사용할 변수 설정\n",
    "# 노이즈로 이미지를 생성\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구분자 신경망에 사용할 변수 설정\n",
    "# 이미지를 넣고 가짜인지 진짜인지 판별\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구분자는 실제 이미지와 생성한 이미지를 받아 가짜인지를 구별한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 신경망\n",
    "# 무작위로 생성한 노이즈를 받아 가중치와 편향을 반영하여 \n",
    "# 실제 이미지와 같은 크기의 가짜 결괏값을 반환한다.\n",
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구분자 신경망\n",
    "# 0~1 사이의 진짜/가짜 여부를 판단한 결과를 반환\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무작위한 노이즈를 만들어주는 유틸리티 함수 정의\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size=(batch_size, n_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노이즈 Z를 이용해 가짜 이미지를 만들 생성자 G를 만들고\n",
    "G = generator(Z)\n",
    "# G가 만든 가짜 이미지와 진짜 이미지 X를 각각 구분자에 넣어\n",
    "# 입력한 이미지가 진짜인지를 판별하도록 합니다.\n",
    "D_gene = discriminator(G)\n",
    "D_real = discriminator(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 손실값을 구합니다.\n",
    "\n",
    "1. 생성자가 만든 이미지를 구분자가 가짜라고 판단하도록 하는 손실값(경찰 학습용)\n",
    "2. 진짜라고 판단하도록 하는 손실값(위조지폐범 학습용)\n",
    "\n",
    "경찰(discriminator)를 학습시키려면 \n",
    "\n",
    "1. 진짜 이미지 판별값 D_real은 1에 가까워야 하고\n",
    "2. 가짜 이미지 판별값 D_gene은 0에 가까워야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D-real은 1에 가까워질 수록 좋고, D_gene은 0에 가까울 수록 좋음\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위조지폐범 학습은 가짜 이미지 판별값 D-gene을 1에 가깝게 만들면 됩니다.\n",
    "\n",
    "- 즉 가짜 이미지를 진짜라고 판별해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_G = tf.reduce_mean(tf.log(D_gene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN의 학습은 loss_D와 loss_G 모두를 최대화하는 것입니다.\n",
    "\n",
    "- 다만 이 둘은 서로 연관되어 있어서 항상 같이 증가하지는 않습니다.\n",
    "- 경찰이 잘하면 위조지폐범이 실패하고, 반대의 경우에도 마찬가지이기 때문\n",
    "\n",
    "![GAN_3](GAN_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할 때에 구분자와 생성자 각각의 변수만 학습되도록 변수로 넘겨줌\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss값을 최대화 하기 위해 음수를 붙여서 학습합니다.\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "    -loss_D, var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "    -loss_G, var_list=G_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금까지는 손실값을 1개만 학습시켰지만 이번에는 2개를 학습시킨다는 점이 다릅니다.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "loss_var_D, loss_var_G = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 D loss: -0.5403 G loss: -2.055\n",
      "Epoch: 0001 D loss: -0.3983 G loss: -2.407\n",
      "Epoch: 0002 D loss: -0.1097 G loss: -3.156\n",
      "Epoch: 0003 D loss: -0.4275 G loss: -1.488\n",
      "Epoch: 0004 D loss: -0.3924 G loss: -1.939\n",
      "Epoch: 0005 D loss: -0.2872 G loss: -2.873\n",
      "Epoch: 0006 D loss: -0.2407 G loss: -2.346\n",
      "Epoch: 0007 D loss: -0.2423 G loss: -2.797\n",
      "Epoch: 0008 D loss: -0.2207 G loss: -2.756\n",
      "Epoch: 0009 D loss: -0.4506 G loss: -2.201\n",
      "Epoch: 0010 D loss: -0.3987 G loss: -2.202\n",
      "Epoch: 0011 D loss: -0.3482 G loss: -2.234\n",
      "Epoch: 0012 D loss: -0.3926 G loss: -2.337\n",
      "Epoch: 0013 D loss: -0.4399 G loss: -2.416\n",
      "Epoch: 0014 D loss: -0.3892 G loss: -2.414\n",
      "Epoch: 0015 D loss: -0.4375 G loss: -2.216\n",
      "Epoch: 0016 D loss: -0.5471 G loss: -2.077\n",
      "Epoch: 0017 D loss: -0.4305 G loss: -2.202\n",
      "Epoch: 0018 D loss: -0.4553 G loss: -2.365\n",
      "Epoch: 0019 D loss: -0.2835 G loss: -2.798\n",
      "Epoch: 0020 D loss: -0.4252 G loss: -2.297\n",
      "Epoch: 0021 D loss: -0.4786 G loss: -2.463\n",
      "Epoch: 0022 D loss: -0.4576 G loss: -2.516\n",
      "Epoch: 0023 D loss: -0.4616 G loss: -2.253\n",
      "Epoch: 0024 D loss: -0.3796 G loss: -2.197\n",
      "Epoch: 0025 D loss: -0.5095 G loss: -2.382\n",
      "Epoch: 0026 D loss: -0.4682 G loss: -2.577\n",
      "Epoch: 0027 D loss: -0.4415 G loss: -2.264\n",
      "Epoch: 0028 D loss: -0.383 G loss: -2.436\n",
      "Epoch: 0029 D loss: -0.5317 G loss: -2.528\n",
      "Epoch: 0030 D loss: -0.6048 G loss: -2.577\n",
      "Epoch: 0031 D loss: -0.5272 G loss: -2.448\n",
      "Epoch: 0032 D loss: -0.5985 G loss: -2.208\n",
      "Epoch: 0033 D loss: -0.6166 G loss: -2.255\n",
      "Epoch: 0034 D loss: -0.6375 G loss: -2.25\n",
      "Epoch: 0035 D loss: -0.5915 G loss: -2.073\n",
      "Epoch: 0036 D loss: -0.6657 G loss: -2.389\n",
      "Epoch: 0037 D loss: -0.8122 G loss: -2.102\n",
      "Epoch: 0038 D loss: -0.6477 G loss: -1.926\n",
      "Epoch: 0039 D loss: -0.7362 G loss: -2.364\n",
      "Epoch: 0040 D loss: -0.6601 G loss: -2.002\n",
      "Epoch: 0041 D loss: -0.764 G loss: -2.325\n",
      "Epoch: 0042 D loss: -0.6619 G loss: -2.043\n",
      "Epoch: 0043 D loss: -0.646 G loss: -2.237\n",
      "Epoch: 0044 D loss: -0.6392 G loss: -2.168\n",
      "Epoch: 0045 D loss: -0.7626 G loss: -1.928\n",
      "Epoch: 0046 D loss: -0.6226 G loss: -2.133\n",
      "Epoch: 0047 D loss: -0.7947 G loss: -2.015\n",
      "Epoch: 0048 D loss: -0.7797 G loss: -1.879\n",
      "Epoch: 0049 D loss: -0.6827 G loss: -2.371\n",
      "Epoch: 0050 D loss: -0.8479 G loss: -1.953\n",
      "Epoch: 0051 D loss: -0.7712 G loss: -2.352\n",
      "Epoch: 0052 D loss: -0.7426 G loss: -2.093\n",
      "Epoch: 0053 D loss: -0.7006 G loss: -1.954\n",
      "Epoch: 0054 D loss: -0.7607 G loss: -2.015\n",
      "Epoch: 0055 D loss: -0.8152 G loss: -1.819\n",
      "Epoch: 0056 D loss: -0.7461 G loss: -1.878\n",
      "Epoch: 0057 D loss: -0.8015 G loss: -1.946\n",
      "Epoch: 0058 D loss: -0.7222 G loss: -1.923\n",
      "Epoch: 0059 D loss: -0.6775 G loss: -1.821\n",
      "Epoch: 0060 D loss: -0.8991 G loss: -1.552\n",
      "Epoch: 0061 D loss: -0.9832 G loss: -2.014\n",
      "Epoch: 0062 D loss: -0.7257 G loss: -2.203\n",
      "Epoch: 0063 D loss: -0.7147 G loss: -1.824\n",
      "Epoch: 0064 D loss: -0.8108 G loss: -1.942\n",
      "Epoch: 0065 D loss: -0.7283 G loss: -1.87\n",
      "Epoch: 0066 D loss: -0.8793 G loss: -1.803\n",
      "Epoch: 0067 D loss: -0.7801 G loss: -1.759\n",
      "Epoch: 0068 D loss: -0.7235 G loss: -1.678\n",
      "Epoch: 0069 D loss: -0.72 G loss: -1.944\n",
      "Epoch: 0070 D loss: -0.8144 G loss: -1.845\n",
      "Epoch: 0071 D loss: -0.9658 G loss: -1.701\n",
      "Epoch: 0072 D loss: -0.7508 G loss: -1.97\n",
      "Epoch: 0073 D loss: -0.9013 G loss: -1.796\n",
      "Epoch: 0074 D loss: -0.9247 G loss: -1.755\n",
      "Epoch: 0075 D loss: -0.7298 G loss: -1.834\n",
      "Epoch: 0076 D loss: -0.8005 G loss: -1.75\n",
      "Epoch: 0077 D loss: -0.813 G loss: -1.562\n",
      "Epoch: 0078 D loss: -0.9089 G loss: -1.592\n",
      "Epoch: 0079 D loss: -0.9701 G loss: -1.662\n",
      "Epoch: 0080 D loss: -0.8204 G loss: -1.654\n",
      "Epoch: 0081 D loss: -0.752 G loss: -1.701\n",
      "Epoch: 0082 D loss: -0.6881 G loss: -1.798\n",
      "Epoch: 0083 D loss: -0.8253 G loss: -1.729\n",
      "Epoch: 0084 D loss: -0.775 G loss: -1.743\n",
      "Epoch: 0085 D loss: -0.7121 G loss: -2.028\n",
      "Epoch: 0086 D loss: -0.8369 G loss: -1.654\n",
      "Epoch: 0087 D loss: -0.9623 G loss: -1.558\n",
      "Epoch: 0088 D loss: -0.6581 G loss: -1.771\n",
      "Epoch: 0089 D loss: -0.7106 G loss: -1.911\n",
      "Epoch: 0090 D loss: -0.7801 G loss: -1.764\n",
      "Epoch: 0091 D loss: -0.9376 G loss: -1.461\n",
      "Epoch: 0092 D loss: -0.8213 G loss: -1.641\n",
      "Epoch: 0093 D loss: -0.7691 G loss: -1.932\n",
      "Epoch: 0094 D loss: -0.8332 G loss: -1.79\n",
      "Epoch: 0095 D loss: -0.7209 G loss: -1.871\n",
      "Epoch: 0096 D loss: -0.8973 G loss: -1.737\n",
      "Epoch: 0097 D loss: -0.7636 G loss: -1.981\n",
      "Epoch: 0098 D loss: -0.6342 G loss: -2.005\n",
      "Epoch: 0099 D loss: -0.8962 G loss: -1.694\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "# 미니배치로 학습을 반복합니다.\n",
    "# 구분자는 X 값을,\n",
    "# 생성자는 노이즈인 Z 값을 받습니다.\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                feed_dict={X: batch_xs, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                feed_dict={Z: noise})\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "         'D loss: {:.4}'.format(loss_val_D),\n",
    "         'G loss: {:.4}'.format(loss_val_G))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "        \n",
    "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "        \n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "        \n",
    "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)),\n",
    "                   bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print('최적화 완료!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "n_hidden = 255\n",
    "n_input = 28 * 28\n",
    "n_noise = 128 # 생성자의 입력값으로 사용할 노이즈의 크기\n",
    "\n",
    "# 이미지를 넣을 X와 이미지에 들어가는 노이즈를 넣을 Z를 추가한다.\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
    "\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
    "    return output\n",
    "\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
    "    return output\n",
    "\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size=(batch_size, n_noise))\n",
    "\n",
    "G = generator(Z)\n",
    "D_gene = discriminator(G)\n",
    "D_real = discriminator(X)\n",
    "\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))\n",
    "\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "    -loss_D, var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "    -loss_G, var_list=G_var_list)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "loss_var_D, loss_var_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                feed_dict={X: batch_xs, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                feed_dict={Z: noise})\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "         'D loss: {:.4}'.format(loss_val_D),\n",
    "         'G loss: {:.4}'.format(loss_val_G))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "        \n",
    "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "        \n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "        \n",
    "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)),\n",
    "                   bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print('최적화 완료!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 원하는 숫자 생성하기\n",
    "\n",
    "이번에는 숫자를 무작위로 생성하지 않고 원하는 숫자를 지정해 생성하는 모델을 만들어보겠습니다.\n",
    "\n",
    "- 여기서는 간단하게 노이즈에 레이블 데이터를 힌트로 넣어주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "n_hidden = 255\n",
    "n_input = 28 * 28\n",
    "n_noise = 128 \n",
    "n_class = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 노이즈와 실제 이미지에 해당하는 숫자를 힌트로 넣어주는 용도로 사용\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성자 신경망을 구성하는데 이번에는 변수를 선언하지 않고 `tf.layers`를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise, labels):\n",
    "    # 학습하는 변수를 지정할 수 있음\n",
    "    with tf.variable_scope('generator'):\n",
    "        inputs = tf.concat([noise, labels], 1)\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, n_input,\n",
    "                                activation=tf.nn.sigmoid)\n",
    "    return output\n",
    "\n",
    "def discriminator(inputs, labels, reuse=None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        # 진짜 이미지를 판별할 때와 가짜 이미지를 판별할 때 똑같은 변수를 사용해야 함\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        inputs = tf.concat([inputs, labels], 1)\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                activation=tf.nn.relu)\n",
    "        # 손실값 계산에 cross_entropy를 사용하기 위해 여기서는 사용하지 않음\n",
    "        output = tf.layers.dense(hidden, 1,\n",
    "                                activation=None)\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z, Y)\n",
    "D_real = discriminator(X, Y)\n",
    "# 가짜 이미지 구분자를 만들 때는 진짜 이미지 구분자에서 사용한 변수들을 재사용하도록\n",
    "# reuse 옵션을 True로 설정\n",
    "D_gene = discriminator(G, Y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구분자(discriminator)의 손실 함수를 만들 차례입니다.\n",
    "# D_real은 1에 가까워야 합니다. \n",
    "# ones_like를 통해 1로 채워진 값과 비교합니다\n",
    "loss_D_real = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=D_real, labels=tf.ones_like(D_real)))\n",
    "# D_gene은 0에 가까워야 합니다. \n",
    "# ones_like를 통해 0으로 채워진 값과 비교합니다\n",
    "loss_D_gene = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=D_gene, labels=tf.zeros_like(D_gene)))\n",
    "\n",
    "# 이 값을 최소화하면 경찰을 학습시킬 수 있습니다.\n",
    "loss_D = loss_D_real + loss_D_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자(generator)의 손실 함수를 만들 차례입니다.\n",
    "# 생성자의 D_gene은 1에 가까워야 합니다.\n",
    "loss_G = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=D_gene, labels=tf.ones_like(D_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_scope에서 사용된 변수들을 가져와 최적화 함수에 전달\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                              scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                              scope='generator')\n",
    "\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D,\n",
    "                                            var_list=vars_D)\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G,\n",
    "                                            var_list=vars_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 D loss: 0.005344 G loss: 7.659\n",
      "Epoch: 0001 D loss: 0.008757 G loss: 9.786\n",
      "Epoch: 0002 D loss: 0.01028 G loss: 8.461\n",
      "Epoch: 0003 D loss: 0.0194 G loss: 6.601\n",
      "Epoch: 0004 D loss: 0.0136 G loss: 8.135\n",
      "Epoch: 0005 D loss: 0.06313 G loss: 6.373\n",
      "Epoch: 0006 D loss: 0.05157 G loss: 6.581\n",
      "Epoch: 0007 D loss: 0.07335 G loss: 7.153\n",
      "Epoch: 0008 D loss: 0.1555 G loss: 6.3\n",
      "Epoch: 0009 D loss: 0.1197 G loss: 6.685\n",
      "Epoch: 0010 D loss: 0.406 G loss: 4.718\n",
      "Epoch: 0011 D loss: 0.3326 G loss: 5.213\n",
      "Epoch: 0012 D loss: 0.3472 G loss: 5.015\n",
      "Epoch: 0013 D loss: 0.3094 G loss: 4.307\n",
      "Epoch: 0014 D loss: 0.5169 G loss: 3.894\n",
      "Epoch: 0015 D loss: 0.5524 G loss: 3.958\n",
      "Epoch: 0016 D loss: 0.5442 G loss: 3.523\n",
      "Epoch: 0017 D loss: 0.3521 G loss: 3.856\n",
      "Epoch: 0018 D loss: 0.4923 G loss: 3.285\n",
      "Epoch: 0019 D loss: 0.5635 G loss: 3.403\n",
      "Epoch: 0020 D loss: 0.3957 G loss: 3.183\n",
      "Epoch: 0021 D loss: 0.5347 G loss: 3.021\n",
      "Epoch: 0022 D loss: 0.7371 G loss: 3.186\n",
      "Epoch: 0023 D loss: 0.595 G loss: 2.658\n",
      "Epoch: 0024 D loss: 0.6335 G loss: 2.575\n",
      "Epoch: 0025 D loss: 0.7023 G loss: 2.61\n",
      "Epoch: 0026 D loss: 0.5913 G loss: 2.394\n",
      "Epoch: 0027 D loss: 0.6955 G loss: 2.468\n",
      "Epoch: 0028 D loss: 0.6413 G loss: 2.477\n",
      "Epoch: 0029 D loss: 0.8493 G loss: 1.931\n",
      "Epoch: 0030 D loss: 0.5824 G loss: 2.332\n",
      "Epoch: 0031 D loss: 0.7039 G loss: 2.235\n",
      "Epoch: 0032 D loss: 0.6682 G loss: 2.372\n",
      "Epoch: 0033 D loss: 0.5775 G loss: 2.87\n",
      "Epoch: 0034 D loss: 0.7867 G loss: 2.367\n",
      "Epoch: 0035 D loss: 0.7642 G loss: 2.441\n",
      "Epoch: 0036 D loss: 0.6529 G loss: 2.216\n",
      "Epoch: 0037 D loss: 0.4886 G loss: 2.588\n",
      "Epoch: 0038 D loss: 0.7907 G loss: 2.136\n",
      "Epoch: 0039 D loss: 0.5162 G loss: 2.431\n",
      "Epoch: 0040 D loss: 0.7749 G loss: 2.027\n",
      "Epoch: 0041 D loss: 0.6808 G loss: 2.108\n",
      "Epoch: 0042 D loss: 0.6308 G loss: 2.316\n",
      "Epoch: 0043 D loss: 0.7918 G loss: 2.187\n",
      "Epoch: 0044 D loss: 0.6299 G loss: 1.979\n",
      "Epoch: 0045 D loss: 0.6098 G loss: 2.244\n",
      "Epoch: 0046 D loss: 0.6356 G loss: 2.229\n",
      "Epoch: 0047 D loss: 0.6103 G loss: 2.299\n",
      "Epoch: 0048 D loss: 0.6215 G loss: 2.493\n",
      "Epoch: 0049 D loss: 0.9101 G loss: 1.85\n",
      "Epoch: 0050 D loss: 0.6073 G loss: 2.366\n",
      "Epoch: 0051 D loss: 0.6992 G loss: 1.91\n",
      "Epoch: 0052 D loss: 0.7614 G loss: 2.213\n",
      "Epoch: 0053 D loss: 0.7798 G loss: 1.895\n",
      "Epoch: 0054 D loss: 0.748 G loss: 1.964\n",
      "Epoch: 0055 D loss: 0.7095 G loss: 2.264\n",
      "Epoch: 0056 D loss: 0.7736 G loss: 1.836\n",
      "Epoch: 0057 D loss: 0.838 G loss: 1.902\n",
      "Epoch: 0058 D loss: 0.8805 G loss: 1.995\n",
      "Epoch: 0059 D loss: 0.7947 G loss: 2.168\n",
      "Epoch: 0060 D loss: 0.7465 G loss: 2.178\n",
      "Epoch: 0061 D loss: 0.7226 G loss: 2.09\n",
      "Epoch: 0062 D loss: 0.5862 G loss: 2.008\n",
      "Epoch: 0063 D loss: 0.9011 G loss: 1.727\n",
      "Epoch: 0064 D loss: 0.7046 G loss: 2.071\n",
      "Epoch: 0065 D loss: 0.611 G loss: 2.178\n",
      "Epoch: 0066 D loss: 0.7093 G loss: 2.254\n",
      "Epoch: 0067 D loss: 0.7797 G loss: 2.102\n",
      "Epoch: 0068 D loss: 0.601 G loss: 2.124\n",
      "Epoch: 0069 D loss: 0.7349 G loss: 2.312\n",
      "Epoch: 0070 D loss: 0.8091 G loss: 1.772\n",
      "Epoch: 0071 D loss: 0.8424 G loss: 2.069\n",
      "Epoch: 0072 D loss: 0.7327 G loss: 2.012\n",
      "Epoch: 0073 D loss: 0.8767 G loss: 1.923\n",
      "Epoch: 0074 D loss: 0.9725 G loss: 1.764\n",
      "Epoch: 0075 D loss: 0.6046 G loss: 2.207\n",
      "Epoch: 0076 D loss: 0.8255 G loss: 2.047\n",
      "Epoch: 0077 D loss: 0.7771 G loss: 1.975\n",
      "Epoch: 0078 D loss: 0.8447 G loss: 2.001\n",
      "Epoch: 0079 D loss: 0.7908 G loss: 2.254\n",
      "Epoch: 0080 D loss: 0.5793 G loss: 2.14\n",
      "Epoch: 0081 D loss: 0.7707 G loss: 2.103\n",
      "Epoch: 0082 D loss: 0.7645 G loss: 2.062\n",
      "Epoch: 0083 D loss: 0.8498 G loss: 1.671\n",
      "Epoch: 0084 D loss: 0.8348 G loss: 2.354\n",
      "Epoch: 0085 D loss: 0.9605 G loss: 2.04\n",
      "Epoch: 0086 D loss: 0.7248 G loss: 2.227\n",
      "Epoch: 0087 D loss: 0.6305 G loss: 1.894\n",
      "Epoch: 0088 D loss: 0.7825 G loss: 1.815\n",
      "Epoch: 0089 D loss: 0.6611 G loss: 2.018\n",
      "Epoch: 0090 D loss: 0.7444 G loss: 2.176\n",
      "Epoch: 0091 D loss: 0.9524 G loss: 1.856\n",
      "Epoch: 0092 D loss: 0.7126 G loss: 2.2\n",
      "Epoch: 0093 D loss: 0.8545 G loss: 1.765\n",
      "Epoch: 0094 D loss: 0.6962 G loss: 2.156\n",
      "Epoch: 0095 D loss: 0.7894 G loss: 1.973\n",
      "Epoch: 0096 D loss: 0.8792 G loss: 1.944\n",
      "Epoch: 0097 D loss: 0.864 G loss: 1.903\n",
      "Epoch: 0098 D loss: 0.6123 G loss: 1.896\n",
      "Epoch: 0099 D loss: 0.716 G loss: 2.231\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                feed_dict={Y: batch_ys, Z: noise})\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "         'D loss: {:.4}'.format(loss_val_D),\n",
    "         'G loss: {:.4}'.format(loss_val_G))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Y: mnist.test.labels[:sample_size],\n",
    "                                         Z: noise})\n",
    "        \n",
    "        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "        \n",
    "        for i in range(sample_size):\n",
    "            ax[0][i].set_axis_off()\n",
    "            ax[1][i].set_axis_off()\n",
    "            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "        \n",
    "        plt.savefig('samples2/{}.png'.format(str(epoch).zfill(3)),\n",
    "                   bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print('최적화 완료!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
