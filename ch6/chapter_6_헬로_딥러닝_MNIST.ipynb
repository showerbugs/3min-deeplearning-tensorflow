{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 헬로 딥러닝 MNIST\n",
    "\n",
    "MNIST 데이터 셋을 신경망으로 학습시켜 보겠습니다.\n",
    "\n",
    "- MNIST는 손으로 쓴 숫자들의 이미지를 모아놓은 데이터셋\n",
    "- 0~9까지의 숫자를 28x28 픽셀 크기의 이미지로 구성\n",
    "\n",
    "![http://simonwinder.com/wp-content/uploads/2015/07/mnistExamples.png](http://simonwinder.com/wp-content/uploads/2015/07/mnistExamples.png)\n",
    "\n",
    "\n",
    "## one-hot encoding란?\n",
    "\n",
    "![https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/1d8fc59e6a674f1c.png](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/1d8fc59e6a674f1c.png)\n",
    "\n",
    "## 테스트용 데이터를 따로 구분하는 이유\n",
    "\n",
    "머신러닝을 위한 학습 데이터는 항상 학습용과 테스트용으로 분리해서 사용합니다.\n",
    "\n",
    "- Train dataset은 학습을 시킬 때 사용\n",
    "- Test dataset은 학습이 잘 되었는지 확인할 때 사용\n",
    "\n",
    "Train dataset으로 예측을 하면 정확도가 매우 높게 나오지만 새로운 데이터를 예측할 때는 정확도가 매우 떨어지는 경우가 많은 경우가 많습니다. 이런 상태를 보고 **Overfitting**이라 합니다.\n",
    "\n",
    "이러한 현상을 확인하고 방지하기 위해 학습 이후 Test dataset으로 검증해야 합니다.\n",
    "\n",
    "MNIST에서는 Train dataset 6만개와 Test dataset 1만개로 구성되어 있습니다.\n",
    "\n",
    "![6_overfitting](6_overfitting.png)\n",
    "\n",
    "## 6.1 MNIST 학습하기\n",
    "\n",
    "여기서는 텐서플로가 제공하는 데이터셋을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# one_hot 인코딩 방식으로 읽어 들임\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28x28 = 784개\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0~9 10개\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 2개의 hidden layer를 두는 신경만을 구성해보겠습니다.\n",
    "\n",
    "784(input layer) -> 256 (1st hidden layer) -> 256 (2nd hidden layer) -> 10 (output layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_normal은 주어진 표준편차의 청규분포를 가지는 임의의 값을 제공\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST는 데이터가 수만 개라서 여러 개를 한번에 학습시키면 메모리나 CPU 연산에 부하가 많이 걸립니다. \n",
    "\n",
    "- 그렇기 때문에 데이터를 적절한 minibatch로 잘라 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 데이터 전체를 학습하는 일을 총 15번 반복합니다\n",
    "\n",
    "- Train dataset 전체를 한 바퀴 도는 것을 epoch라고 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001 Avg. cost =0.409\n",
      "Epoch:0002 Avg. cost =0.155\n",
      "Epoch:0003 Avg. cost =0.103\n",
      "Epoch:0004 Avg. cost =0.072\n",
      "Epoch:0005 Avg. cost =0.052\n",
      "Epoch:0006 Avg. cost =0.042\n",
      "Epoch:0007 Avg. cost =0.033\n",
      "Epoch:0008 Avg. cost =0.026\n",
      "Epoch:0009 Avg. cost =0.019\n",
      "Epoch:0010 Avg. cost =0.018\n",
      "Epoch:0011 Avg. cost =0.016\n",
      "Epoch:0012 Avg. cost =0.014\n",
      "Epoch:0013 Avg. cost =0.014\n",
      "Epoch:0014 Avg. cost =0.010\n",
      "Epoch:0015 Avg. cost =0.011\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost], \n",
    "                               feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        total_cost += cost_val\n",
    "    print('Epoch:{:04d} Avg. cost ={:.3f}'.format(epoch + 1, total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model을 구동해 나오는 결과는 아래와 같을 것입니다.\n",
    "\n",
    "![6_argmax.png](6_argmax.png)\n",
    "\n",
    "이제 학습이 잘 되었는지 검증해보도록 하겠습니다.\n",
    "\n",
    "- argmax로 가장 큰 값을 가진 인덱스를 가져옵니다\n",
    "- 그 인덱스로 비교해 정확도를 측정합니다.\n",
    "- equal의 반환이 bool이기 때문에 float으로 casting\n",
    "- 그리고 mean(평균)을 측정  \n",
    "    - `(1+0+1+1+0+1) 6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.98\n"
     ]
    }
   ],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                      feed_dict={X: mnist.test.images,\n",
    "                                 Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch:0001 Avg. cost =0.402\n",
      "Epoch:0002 Avg. cost =0.145\n",
      "Epoch:0003 Avg. cost =0.093\n",
      "Epoch:0004 Avg. cost =0.069\n",
      "Epoch:0005 Avg. cost =0.050\n",
      "Epoch:0006 Avg. cost =0.039\n",
      "Epoch:0007 Avg. cost =0.030\n",
      "Epoch:0008 Avg. cost =0.025\n",
      "Epoch:0009 Avg. cost =0.021\n",
      "Epoch:0010 Avg. cost =0.017\n",
      "Epoch:0011 Avg. cost =0.017\n",
      "Epoch:0012 Avg. cost =0.016\n",
      "Epoch:0013 Avg. cost =0.011\n",
      "Epoch:0014 Avg. cost =0.011\n",
      "Epoch:0015 Avg. cost =0.012\n",
      "최적화 완료!\n",
      "정확도: 0.9803\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# one_hot 인코딩 방식으로 읽어 들임\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "# 28x28 = 784개\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0~9 10개\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# random_normal은 주어진 표준편차의 청규분포를 가지는 임의의 값을 제공\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost], \n",
    "                               feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        total_cost += cost_val\n",
    "    print('Epoch:{:04d} Avg. cost ={:.3f}'.format(epoch + 1, total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                      feed_dict={X: mnist.test.images,\n",
    "                                 Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 드롭아웃\n",
    "\n",
    "Dropout은 Overfitting을 막기 위해 사용되는 방법 중 가장 효과가 좋은 방법 중 하나입니다.\n",
    "\n",
    "Dropout의 원리는 학습 시 전체 신경망 중 일부만을 사용하도록 하는 것입니다.\n",
    "\n",
    "- 즉 학습 단계마다 일부 뉴런을 제거함으로써 일부 특징이 특정 뉴런들에 고정되는 것을 막아 가중치의 균형을 잡도록 도와줍니다.\n",
    "- 다만, 학습시간은 증가하게 됩니다.\n",
    "\n",
    "![6_dropout](6_dropout.png)\n",
    "\n",
    "위의 모델에 Dropout을 적용하면 아래처럼 수정하면 됩니다.\n",
    "\n",
    "- keep_prob는 학습시에는 0.8을 넣고 예측시에는 1을 넣어 dropout 비율을 조절하기 위해 사용합니다.\n",
    "\n",
    "```py\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "# 학습 코드\n",
    "_, cost_val = sess.run([optimizer, cost], \n",
    "    feed_dict={X: batch_xs,Y: batch_ys, keep_prob: 0.8})\n",
    "\n",
    "# 예측 코드: keep_prob를 1로 넣어줍니다.\n",
    "print('정확도:', sess.run(accuracy,\n",
    "    feed_dict={X: mnist.test.images,Y: mnist.test.labels, keep_prob: 1})\n",
    "```\n",
    "\n",
    "드롭 아웃을 적용하면 학습이 느리게 진행되기 때문에(학습 속도가 느림) epoch도 더 늘리도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch:0001 Avg. cost =0.443\n",
      "Epoch:0002 Avg. cost =0.166\n",
      "Epoch:0003 Avg. cost =0.114\n",
      "Epoch:0004 Avg. cost =0.091\n",
      "Epoch:0005 Avg. cost =0.074\n",
      "Epoch:0006 Avg. cost =0.062\n",
      "Epoch:0007 Avg. cost =0.053\n",
      "Epoch:0008 Avg. cost =0.048\n",
      "Epoch:0009 Avg. cost =0.043\n",
      "Epoch:0010 Avg. cost =0.038\n",
      "Epoch:0011 Avg. cost =0.035\n",
      "Epoch:0012 Avg. cost =0.031\n",
      "Epoch:0013 Avg. cost =0.030\n",
      "Epoch:0014 Avg. cost =0.029\n",
      "Epoch:0015 Avg. cost =0.025\n",
      "Epoch:0016 Avg. cost =0.028\n",
      "Epoch:0017 Avg. cost =0.024\n",
      "Epoch:0018 Avg. cost =0.022\n",
      "Epoch:0019 Avg. cost =0.021\n",
      "Epoch:0020 Avg. cost =0.020\n",
      "Epoch:0021 Avg. cost =0.020\n",
      "Epoch:0022 Avg. cost =0.019\n",
      "Epoch:0023 Avg. cost =0.021\n",
      "Epoch:0024 Avg. cost =0.016\n",
      "Epoch:0025 Avg. cost =0.019\n",
      "Epoch:0026 Avg. cost =0.017\n",
      "Epoch:0027 Avg. cost =0.017\n",
      "Epoch:0028 Avg. cost =0.017\n",
      "Epoch:0029 Avg. cost =0.017\n",
      "Epoch:0030 Avg. cost =0.016\n",
      "최적화 완료!\n",
      "정확도: 0.9819\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost], \n",
    "                               feed_dict={X: batch_xs, Y: batch_ys, \n",
    "                                          keep_prob: 0.8})\n",
    "        total_cost += cost_val\n",
    "    print('Epoch:{:04d} Avg. cost ={:.3f}'.format(epoch + 1, total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                      feed_dict={X: mnist.test.images,\n",
    "                                 Y: mnist.test.labels,\n",
    "                                 keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 방법으로는 batch normalization이라는 기법도 있는데 영기선 생략하겠습니다.\n",
    "\n",
    "- overfitting를 막아주고 학습 속도도 향상됨\n",
    "\n",
    "## 6.3 matplotlib\n",
    "\n",
    "matplotlib은 시각화를 위한 그래프를 쉽게 그릴 수 있도록 도와주는 파이썬 라이브러리입니다.\n",
    "\n",
    "이번 절에서는 matplotlib을 이용해 학습 결과를 손글씨 이미지로 확인해보는 간단한 예제를 만들어 보겠습니다.\n",
    "\n",
    "앞절에서 작성한 코드에 아래 코드를 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADSCAYAAAB9/7r8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niERCA7KISCQ0IIuIROL/AWUvVQZhcCILAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121d00fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. 테스트 데이터를 이용해 예측 모델을 실행한 결과값을 저장\n",
    "labels = sess.run(model,\n",
    "                 feed_dict={X: mnist.test.images,\n",
    "                            Y: mnist.test.labels,\n",
    "                            keep_prob: 1})\n",
    "\n",
    "# 2. 손글씨를 출력할 그래프를 준비\n",
    "fig = plt.figure()\n",
    "\n",
    "# 3. 테스트 데이터의 첫 번째부터 열 번째까지의 이미지와 예측한 값을 출력\n",
    "for i in range(10):\n",
    "    # 4. 2행 5열의 그래프를 만들고 i+1번째 숫자 이미지를 출력\n",
    "    subplot = fig.add_subplot(2, 5, i+1)\n",
    "    # 5. 깨끗한 이미지를 출력하기 위해 눈금을 삭제\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    # 6. 출력한 이미지 위에 예측한 숫자를 출력\n",
    "    subplot.set_title('{}'.format(np.argmax(labels[i])))\n",
    "    # 7. 1차원 배열로 되어 있는 이미지를 28x28로 변형하여 출력\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)),\n",
    "                  cmap=plt.cm.gray_r)\n",
    "# 8. 그래프 출력\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
